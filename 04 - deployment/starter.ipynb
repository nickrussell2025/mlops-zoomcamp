{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c51efaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4acf73a0-51b5-4663-9bb8-8eb947863e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0410d059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version: 1.0.2\n",
      "pandas version: 1.3.5\n",
      "Model loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/share/virtualenvs/04_-_deployment-SeBN4jeX/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DictVectorizer from version 1.5.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/share/virtualenvs/04_-_deployment-SeBN4jeX/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LinearRegression from version 1.5.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "print(f\"sklearn version: {sklearn.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "\n",
    "# Load model\n",
    "with open('model.bin', 'rb') as f:\n",
    "    dv, model = pickle.load(f)\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "132cb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef880a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7836ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.bin', 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41c08294",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4854399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "669fda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = df[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(dicts)\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf532ae7-1897-428c-ba0c-875ccaf7d76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape: (3316216, 20)\n",
      "first few column names: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance']\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset shape: {df.shape}\")\n",
    "print(f\"first few column names: {list(df.columns[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a82b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration column we created:\n",
      "count    3.316216e+06\n",
      "mean     1.499996e+01\n",
      "std      1.060465e+01\n",
      "min      1.000000e+00\n",
      "25%      7.483333e+00\n",
      "50%      1.211667e+01\n",
      "75%      1.930000e+01\n",
      "max      6.000000e+01\n",
      "Name: duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Duration column we created:\")\n",
    "print(df['duration'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d64dd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample trips:\n",
      "  tpep_pickup_datetime tpep_dropoff_datetime   duration\n",
      "0  2023-03-01 00:06:43   2023-03-01 00:16:43  10.000000\n",
      "1  2023-03-01 00:08:25   2023-03-01 00:39:30  31.083333\n",
      "2  2023-03-01 00:15:04   2023-03-01 00:29:26  14.366667\n"
     ]
    }
   ],
   "source": [
    "print(\"sample trips:\")\n",
    "print(df[['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'duration']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b46912a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where these trips went\n",
      "  PULocationID DOLocationID\n",
      "0          238           42\n",
      "1          138          231\n",
      "2          140          186\n"
     ]
    }
   ],
   "source": [
    "print(\"where these trips went\")\n",
    "print(df[['PULocationID', 'DOLocationID']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0517e0",
   "metadata": {},
   "source": [
    "### question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac26d3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation: 6.247488852238703\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    return df\n",
    "\n",
    "df = read_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet')\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "val_dicts = df[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(f\"Standard deviation: {np.std(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2087178",
   "metadata": {},
   "source": [
    "### question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6fabda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 65.5M\n"
     ]
    }
   ],
   "source": [
    "year = 2023\n",
    "month = 3\n",
    "\n",
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "\n",
    "df_result = pd.DataFrame({\n",
    "    'ride_id': df['ride_id'],\n",
    "    'predicted_duration': y_pred\n",
    "})\n",
    "\n",
    "output_file = 'predictions.parquet'\n",
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")\n",
    "\n",
    "import os\n",
    "file_size_mb = os.path.getsize(output_file) / (1024*1024)\n",
    "print(f\"File size: {file_size_mb:.1f}M\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOps Deployment (pipenv)",
   "language": "python",
   "name": "mlops-deployment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
