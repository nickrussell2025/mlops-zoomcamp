{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c27d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file hash: ed21c77dd95b293b0d7ef6682f498c81\n",
      "File size: 17376 bytes\n",
      "File modified: 1750063585.179188\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "\n",
    "# Check if the file is actually changing\n",
    "with open('model.bin', 'rb') as f:\n",
    "    file_hash = hashlib.md5(f.read()).hexdigest()\n",
    "    \n",
    "print(f\"Model file hash: {file_hash}\")\n",
    "print(f\"File size: {os.path.getsize('model.bin')} bytes\")\n",
    "print(f\"File modified: {os.path.getmtime('model.bin')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf5de27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version: 1.0.2\n",
      "⚠️  Got 2 warnings:\n",
      "   Trying to unpickle estimator DictVectorizer from version 1.5.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "   Trying to unpickle estimator LinearRegression from version 1.5.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "import sklearn\n",
    "\n",
    "print(f\"sklearn version: {sklearn.__version__}\")\n",
    "\n",
    "# Capture warnings explicitly\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    warnings.simplefilter(\"always\")\n",
    "    \n",
    "    with open('model.bin', 'rb') as f:\n",
    "        dv, model = pickle.load(f)\n",
    "    \n",
    "    if w:\n",
    "        print(f\"⚠️  Got {len(w)} warnings:\")\n",
    "        for warning in w:\n",
    "            print(f\"   {warning.message}\")\n",
    "    else:\n",
    "        print(\"✅ No warnings!\")\n",
    "\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c51efaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4acf73a0-51b5-4663-9bb8-8eb947863e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0410d059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version: 1.0.2\n",
      "pandas version: 1.3.5\n",
      "Model loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/share/virtualenvs/04_-_deployment-SeBN4jeX/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DictVectorizer from version 1.5.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/share/virtualenvs/04_-_deployment-SeBN4jeX/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LinearRegression from version 1.5.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "print(f\"sklearn version: {sklearn.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "\n",
    "# Load model\n",
    "with open('model.bin', 'rb') as f:\n",
    "    dv, model = pickle.load(f)\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "419f1d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- -----------\n",
      "anyio                     4.7.0\n",
      "argon2-cffi               21.3.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "asttokens                 3.0.0\n",
      "async-lru                 2.0.4\n",
      "attrs                     24.3.0\n",
      "babel                     2.16.0\n",
      "backcall                  0.2.0\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.2.0\n",
      "Bottleneck                1.4.2\n",
      "Brotli                    1.0.9\n",
      "certifi                   2025.4.26\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.3.2\n",
      "comm                      0.2.1\n",
      "debugpy                   1.8.11\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "exceptiongroup            1.2.0\n",
      "executing                 0.8.3\n",
      "fastjsonschema            2.20.0\n",
      "h11                       0.16.0\n",
      "httpcore                  1.0.9\n",
      "httpx                     0.28.1\n",
      "idna                      3.7\n",
      "importlib_metadata        8.5.0\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.15.0\n",
      "ipywidgets                8.1.5\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.6\n",
      "joblib                    1.4.2\n",
      "json5                     0.9.25\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2023.7.1\n",
      "jupyter                   1.1.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.12.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.15.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.3.4\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "jupyterlab_widgets        3.0.13\n",
      "MarkupSafe                3.0.2\n",
      "matplotlib-inline         0.1.6\n",
      "mistune                   3.1.2\n",
      "mkl_fft                   1.3.11\n",
      "mkl_random                1.2.8\n",
      "mkl-service               2.4.0\n",
      "nbclient                  0.10.2\n",
      "nbconvert                 7.16.6\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "notebook                  7.3.2\n",
      "notebook_shim             0.2.4\n",
      "numexpr                   2.10.1\n",
      "numpy                     1.26.4\n",
      "overrides                 7.4.0\n",
      "packaging                 24.2\n",
      "pandas                    2.2.3\n",
      "pandocfilters             1.5.0\n",
      "parso                     0.8.4\n",
      "pexpect                   4.8.0\n",
      "pickleshare               0.7.5\n",
      "pip                       25.1\n",
      "platformdirs              4.3.7\n",
      "prometheus_client         0.21.1\n",
      "prompt-toolkit            3.0.43\n",
      "psutil                    5.9.0\n",
      "ptyprocess                0.7.0\n",
      "pure-eval                 0.2.2\n",
      "pyarrow                   19.0.0\n",
      "pycparser                 2.21\n",
      "Pygments                  2.19.1\n",
      "PyQt6                     6.7.1\n",
      "PyQt6_sip                 13.9.1\n",
      "PySocks                   1.7.1\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        3.2.1\n",
      "pytz                      2024.1\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.2.0\n",
      "qtconsole                 5.6.1\n",
      "QtPy                      2.4.1\n",
      "referencing               0.30.2\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.22.3\n",
      "scikit-learn              1.5.0\n",
      "scipy                     1.13.1\n",
      "Send2Trash                1.8.2\n",
      "setuptools                78.1.1\n",
      "sip                       6.10.0\n",
      "six                       1.17.0\n",
      "sniffio                   1.3.0\n",
      "soupsieve                 2.5\n",
      "stack-data                0.2.0\n",
      "terminado                 0.17.1\n",
      "threadpoolctl             3.5.0\n",
      "tinycss2                  1.4.0\n",
      "tomli                     2.0.1\n",
      "tornado                   6.5.1\n",
      "traitlets                 5.14.3\n",
      "typing_extensions         4.12.2\n",
      "tzdata                    2025.2\n",
      "urllib3                   2.3.0\n",
      "wcwidth                   0.2.5\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "wheel                     0.45.1\n",
      "widgetsnbextension        4.0.13\n",
      "zipp                      3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "132cb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef880a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7836ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.bin', 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41c08294",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4854399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "669fda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = df[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(dicts)\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf532ae7-1897-428c-ba0c-875ccaf7d76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape: (3316216, 20)\n",
      "first few column names: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance']\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset shape: {df.shape}\")\n",
    "print(f\"first few column names: {list(df.columns[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a82b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration column we created:\n",
      "count    3.316216e+06\n",
      "mean     1.499996e+01\n",
      "std      1.060465e+01\n",
      "min      1.000000e+00\n",
      "25%      7.483333e+00\n",
      "50%      1.211667e+01\n",
      "75%      1.930000e+01\n",
      "max      6.000000e+01\n",
      "Name: duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Duration column we created:\")\n",
    "print(df['duration'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d64dd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample trips:\n",
      "  tpep_pickup_datetime tpep_dropoff_datetime   duration\n",
      "0  2023-03-01 00:06:43   2023-03-01 00:16:43  10.000000\n",
      "1  2023-03-01 00:08:25   2023-03-01 00:39:30  31.083333\n",
      "2  2023-03-01 00:15:04   2023-03-01 00:29:26  14.366667\n"
     ]
    }
   ],
   "source": [
    "print(\"sample trips:\")\n",
    "print(df[['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'duration']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b46912a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where these trips went\n",
      "  PULocationID DOLocationID\n",
      "0          238           42\n",
      "1          138          231\n",
      "2          140          186\n"
     ]
    }
   ],
   "source": [
    "print(\"where these trips went\")\n",
    "print(df[['PULocationID', 'DOLocationID']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94792169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what your model predicted for those same 3 trips\n",
      "[16.24590642 26.1347962  11.88426424]\n",
      "\n",
      "actual vs predicted:\n",
      "trip 1: actual 10.0 min, predicted16.2 min\n",
      "trip 2: actual 31.1 min, predicted26.1 min\n",
      "trip 3: actual 14.4 min, predicted11.9 min\n"
     ]
    }
   ],
   "source": [
    "print(\"what your model predicted for those same 3 trips\")\n",
    "print(y_pred[:3])\n",
    "print(\"\\nactual vs predicted:\")\n",
    "for i in range(3):\n",
    "  print(f\"trip {i+1}: actual {df['duration'].iloc[i]:.1f} min, predicted{y_pred[i]:.1f} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0517e0",
   "metadata": {},
   "source": [
    "### question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa43df9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation: 6.247488852238703\n"
     ]
    }
   ],
   "source": [
    "# Run the Q1 calculation\n",
    "std_deviation = np.std(y_pred)\n",
    "print(f\"Standard deviation: {std_deviation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac26d3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation: 6.247488852238703\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    return df\n",
    "\n",
    "df = read_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet')\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "val_dicts = df[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(f\"Standard deviation: {np.std(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2087178",
   "metadata": {},
   "source": [
    "### question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c6fabda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 65.5M\n"
     ]
    }
   ],
   "source": [
    "# Q2: Create output file\n",
    "year = 2023\n",
    "month = 3\n",
    "\n",
    "# Create ride_id column\n",
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "\n",
    "# Create results dataframe\n",
    "df_result = pd.DataFrame({\n",
    "    'ride_id': df['ride_id'],\n",
    "    'predicted_duration': y_pred\n",
    "})\n",
    "\n",
    "# Save as parquet\n",
    "output_file = 'predictions.parquet'\n",
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Check file size\n",
    "import os\n",
    "file_size_mb = os.path.getsize(output_file) / (1024*1024)\n",
    "print(f\"File size: {file_size_mb:.1f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716ccabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /home/codespace/.local/share/virtualenvs/04_-_deployment-SeBN4jeX/bin/python\n",
      "Should contain: 04_-_deployment-SeBN4jeX\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Should contain: 04_-_deployment-SeBN4jeX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfa2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOps Deployment (pipenv)",
   "language": "python",
   "name": "mlops-deployment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
